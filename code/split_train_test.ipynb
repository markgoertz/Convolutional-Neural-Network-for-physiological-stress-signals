{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn import model_selection\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ast\n",
    "import dask.dataframe as dd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = os.path.dirname(os.getcwd())\n",
    "DATA_PATH = [\n",
    "                MAIN_PATH + \"/data/wrist_result_df.csv\" \n",
    "            ]\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 32\n",
    "METRIC = [\"EDA\", \"TEMP\", \"BVP\", \"X\", \"Y\", \"Z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for Plotting with Matplotlib\n",
    "\n",
    "In this section, we define methods to visualize data distributions using Matplotlib. These methods help in understanding the class distribution before and after applying SMOTE, as well as the distribution of datasets across training, validation, and test sets.\n",
    "\n",
    "### Plotting Class Distribution Before and After SMOTE\n",
    "\n",
    "The `plot_smote_class_distribution` function plots the class distribution of the training labels before and after applying SMOTE (Synthetic Minority Over-sampling Technique). This visualization helps in understanding how SMOTE balances the class distribution.\n",
    "\n",
    "\n",
    "### Plotting Dataset Distribution\n",
    "\n",
    "The `plot_dataset_distribution` function plots a bar chart showing the sizes of the train, validation, and test sets. This visualization helps in understanding the distribution of samples across different datasets.\n",
    "\n",
    "These methods provide visual insights into the data, which is crucial for understanding and improving the performance of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_smote_class_distribution(y_train, y_train_resampled):\n",
    "    \"\"\"\n",
    "    Plots the class distribution before and after applying SMOTE.\n",
    "\n",
    "    Parameters:\n",
    "    - y_train: Original training labels.\n",
    "    - y_train_resampled: Training labels after applying SMOTE.\n",
    "    \"\"\"\n",
    "    # Class distribution before SMOTE\n",
    "    class_distribution_before = Counter(y_train)\n",
    "    # Class distribution after SMOTE\n",
    "    class_distribution_after = Counter(y_train_resampled)\n",
    "\n",
    "    # Define labels\n",
    "    labels = ['No Stress', 'Stress']\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot before SMOTE\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(labels, class_distribution_before.values(), color='blue')\n",
    "    plt.title('Class Distribution Before SMOTE')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks([0, 1], labels)\n",
    "\n",
    "    # Plot after SMOTE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(labels, class_distribution_after.values(), color='green')\n",
    "    plt.title('Class Distribution After SMOTE')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks([0, 1], labels)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../images/preprocessing/SMOTE.png\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_distribution(x_train_resampled, y_train_resampled, x_val_resampled, y_val_resampled, \n",
    "                              x_test_subject_1, y_test_subject_1, \n",
    "                              x_test_subject_2, y_test_subject_2):\n",
    "\n",
    "    dataset_names = ['Train', 'Validation', 'Test Subject 1', 'Test Subject 2']\n",
    "    # Calculate lengths for x and y datasets\n",
    "    x_lengths = [len(x_train_resampled), len(x_val_resampled), len(x_test_subject_1), len(x_test_subject_2)]\n",
    "    y_lengths = [len(y_train_resampled), len(y_val_resampled), len(y_test_subject_1), len(y_test_subject_2)]\n",
    "    \n",
    "    # Plotting the bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    bar_width = 0.35  # Width of the bars\n",
    "    index = np.arange(len(dataset_names))\n",
    "    \n",
    "    # Create bar plots for x and y datasets\n",
    "    plt.bar(index, x_lengths, bar_width, color='b', alpha=0.6, label='X (Features)')\n",
    "    plt.bar(index + bar_width, y_lengths, bar_width, color='r', alpha=0.6, label='Y (Labels)')\n",
    "    \n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title('Dataset Distribution')\n",
    "    plt.xticks(index + bar_width / 2, dataset_names)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(\"../images/preprocessing/dataset_distribution.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chunk(file_path, chunk_size, usecols=None, dtype=None):\n",
    "    \"\"\"Read a CSV file in chunks and yield DataFrames.\"\"\"\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size, usecols=usecols, dtype=dtype):\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_paths, chunk_size=100000, usecols=None, dtype=None):\n",
    "    \"\"\"Load data from multiple CSV files in chunks and concatenate them into a single DataFrame.\"\"\"\n",
    "    dataframes = []\n",
    "    total_files = len(file_paths)\n",
    "\n",
    "    # Create a thread pool to read files in chunks in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(read_chunk, file_path, chunk_size, usecols, dtype): file_path for file_path in file_paths}\n",
    "\n",
    "        for i, future in enumerate(as_completed(futures)):\n",
    "            file_path = futures[future]\n",
    "            try:\n",
    "                # Extend dataframes with the result of read_chunk\n",
    "                # Assuming read_chunk returns a list of DataFrames\n",
    "                dataframes.extend(future.result())\n",
    "                print(f\"Completed reading all chunks from {file_path} ({i + 1}/{total_files}).\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunks from {file_path}: {e}\")\n",
    "\n",
    "    # Concatenate all DataFrames into one and return\n",
    "    return pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_subjects(df):\n",
    "    test_df = df[(df['ID'] == 16.0) | (df['ID'] == 17.0)]\n",
    "\n",
    "    # Drop the filtered rows from the original DataFrame\n",
    "    sequences_df = df.drop(test_df.index)\n",
    "\n",
    "    # Reset index for both DataFrames\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    sequences_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    test_subject_1 = test_df[test_df['ID'] == 16.0]\n",
    "    test_subject_2 = test_df[test_df['ID'] == 17.0]\n",
    "\n",
    "    # Check if the test subjects DataFrames are empty\n",
    "    if test_subject_1.empty:\n",
    "        print(\"Warning: No data found for test subject 1 (ID 16.0)\")\n",
    "    if test_subject_2.empty:\n",
    "        print(\"Warning: No data found for test subject 2 (ID 17.0)\")\n",
    "\n",
    "    return test_subject_1, test_subject_2, sequences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_flatten(series_list):\n",
    "    try:\n",
    "        scaler = MinMaxScaler()\n",
    "        return [scaler.fit_transform(np.asarray(series).reshape(-1, 1)).flatten() for series in series_list]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to scale and flatten series: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metrics(df, t_df1, t_df2):\n",
    "    try:\n",
    "        eda_array_list = scale_and_flatten(df[METRIC].apply(eval))\n",
    "        test_subject1_array_list = scale_and_flatten(t_df1[METRIC].apply(eval))\n",
    "        test_subject2_array_list = scale_and_flatten(t_df2[METRIC].apply(eval))\n",
    "\n",
    "        # Print counts\n",
    "        print(f\"EDA list Count: {len(eda_array_list)}\\n Test Subject 1: {len(test_subject1_array_list)} \\n Test Subject 2: {len(test_subject2_array_list)} \")\n",
    "        \n",
    "        return eda_array_list, test_subject1_array_list, test_subject2_array_list\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to process metrics: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_reshape(df, metrics, maxlen):\n",
    "    try:\n",
    "        # Initialize a new DataFrame to store the reshaped data\n",
    "        reshaped_df = pd.DataFrame()\n",
    "\n",
    "        for metric in metrics:\n",
    "            if metric in df.columns:\n",
    "                # Convert the metric column to a list of lists for padding\n",
    "                series_list = df[metric].tolist()\n",
    "\n",
    "                # Convert strings to lists if necessary and handle NaN values\n",
    "                for i in range(len(series_list)):\n",
    "                    if pd.isna(series_list[i]):\n",
    "                        series_list[i] = []\n",
    "                    elif isinstance(series_list[i], str):\n",
    "                        try:\n",
    "                            series_list[i] = ast.literal_eval(series_list[i])\n",
    "                        except Exception as e:\n",
    "                            raise ValueError(f\"Error converting string to list at index {i}: {e}\")\n",
    "\n",
    "                # Pad the series for the current metric\n",
    "                padded = pad_sequences(series_list, maxlen=maxlen, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "                # Convert the padded array to a DataFrame\n",
    "                reshaped_metric_df = pd.DataFrame(padded, columns=[f'{metric}_{i}' for i in range(maxlen)])\n",
    "                reshaped_df[metric] = reshaped_metric_df.values.tolist()\n",
    "\n",
    "        return reshaped_df  # Ensure this returns a DataFrame\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to pad and reshape series: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(x_train, y_train, x_val, y_val, metrics, max_sequence_length=32, random_state=42):\n",
    "    # Initialize SMOTE\n",
    "    smote = SMOTE(random_state=random_state)\n",
    "\n",
    "    # Resampling for training data\n",
    "    x_train_array = np.array([np.concatenate([row[i] for i in range(len(metrics))]) for row in x_train.itertuples(index=False)])\n",
    "    x_resampled, y_resampled = smote.fit_resample(x_train_array, y_train.values.ravel())\n",
    "\n",
    "    # Create resampled DataFrame for training data\n",
    "    resampled_data = {metric: [list(x_resampled[i][j * max_sequence_length:(j + 1) * max_sequence_length]) for i in range(len(x_resampled))] for j, metric in enumerate(metrics)}\n",
    "    x_resampled_df = pd.DataFrame(resampled_data)\n",
    "    y_resampled_df = pd.DataFrame(y_resampled, columns=['labels'])\n",
    "\n",
    "    # Resampling for validation data\n",
    "    x_val_array = np.array([np.concatenate([row[i] for i in range(len(metrics))]) for row in x_val.itertuples(index=False)])\n",
    "    x_val_resampled, y_val_resampled = smote.fit_resample(x_val_array, y_val.values.ravel())\n",
    "\n",
    "    # Create resampled DataFrame for validation data\n",
    "    resampled_val_data = {metric: [list(x_val_resampled[i][j * max_sequence_length:(j + 1) * max_sequence_length]) for i in range(len(x_val_resampled))] for j, metric in enumerate(metrics)}\n",
    "    x_val_resampled_df = pd.DataFrame(resampled_val_data)\n",
    "    y_val_resampled_df = pd.DataFrame(y_val_resampled, columns=['labels'])\n",
    "\n",
    "    return x_resampled_df, y_resampled_df, x_val_resampled_df, y_val_resampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test(features_df, labels_array, metrics):\n",
    "    # Prepare DataFrames to hold training and validation features\n",
    "    x_train = pd.DataFrame()\n",
    "    x_val = pd.DataFrame()\n",
    "\n",
    "    # Loop through each metric, splitting the data\n",
    "    for metric in metrics:\n",
    "        if metric in features_df.columns:\n",
    "            # Split the feature for the current metric\n",
    "            train, val = model_selection.train_test_split(\n",
    "                features_df[metric], test_size=0.30, random_state=42, shuffle=True\n",
    "            )\n",
    "            # Add the split data to the respective DataFrames\n",
    "            x_train[metric] = train.reset_index(drop=True)  # Resetting index to align\n",
    "            x_val[metric] = val.reset_index(drop=True)      # Resetting index to align\n",
    "        else:\n",
    "            raise ValueError(f\"Metric '{metric}' not found in features_df.\")\n",
    "\n",
    "    # Split the labels into training and validation sets\n",
    "    y_train, y_val = model_selection.train_test_split(\n",
    "        labels_array, test_size=0.30, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    return x_train, x_val, y_train, y_val  # Ensure these are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_labels(df, t_df1, t_df2, label_column='labels'):\n",
    "    try:\n",
    "        # Extract labels for the main dataset and test subjects\n",
    "        labels_array = pd.DataFrame(df[label_column].reset_index(drop=True), columns=[label_column])\n",
    "        validation_labels_array_subject_1 = pd.DataFrame(t_df1[label_column].reset_index(drop=True), columns=[label_column])\n",
    "        validation_labels_array_subject_2 = pd.DataFrame(t_df2[label_column].reset_index(drop=True), columns=[label_column])\n",
    "\n",
    "        print(\n",
    "            f'Label list Count: {len(labels_array)}\\n'\n",
    "            f\"Labels list Count Subject 1: {len(validation_labels_array_subject_1)}\\n\"\n",
    "            f\"Labels list Count Subject 2: {len(validation_labels_array_subject_2)}\"\n",
    "        )\n",
    "        \n",
    "        return labels_array, validation_labels_array_subject_1, validation_labels_array_subject_2\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to extract labels: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_series(eda_array_list, test_subject1_array_list, test_subject2_array_list):\n",
    "    if not eda_array_list or not test_subject1_array_list or not test_subject2_array_list:\n",
    "        raise ValueError(\"Input lists must not be empty\")\n",
    "    \n",
    "    series_padded = pad_and_reshape(eda_array_list, MAX_SEQUENCE_LENGTH)\n",
    "    x_test_subject_1_padded = pad_and_reshape(test_subject1_array_list, MAX_SEQUENCE_LENGTH)\n",
    "    x_test_subject_2_padded = pad_and_reshape(test_subject2_array_list, MAX_SEQUENCE_LENGTH)\n",
    "    return series_padded, x_test_subject_1_padded, x_test_subject_2_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(y_train, y_val, validation_labels_array_subject_1, validation_labels_array_subject_2):\n",
    "    try:\n",
    "        y_train = np.asarray(y_train).astype(np.int32)\n",
    "        y_val = np.asarray(y_val).astype(np.int32)\n",
    "        y_test_subject_1 = np.asarray(validation_labels_array_subject_1).astype(np.int32)\n",
    "        y_test_subject_2 = np.asarray(validation_labels_array_subject_2).astype(np.int32)\n",
    "        return y_train, y_val, y_test_subject_1, y_test_subject_2\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to convert labels: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_datasets(x_train_resampled, y_train_resampled, x_val_resampled, y_val_resampled, \n",
    "                  processed_test_subject1_dict, y_test_subject_1, \n",
    "                  processed_test_subject2_dict, y_test_subject_2, \n",
    "                  save_directory=\"../data/results/\"):\n",
    "    try:\n",
    "        # Dictionary to store all datasets\n",
    "        datasets = {\n",
    "            \"x_train_resampled\": x_train_resampled,\n",
    "            \"y_train_resampled\": y_train_resampled,\n",
    "            \"x_val_resampled\": x_val_resampled,\n",
    "            \"y_val_resampled\": y_val_resampled,\n",
    "            \"x_test_subject_1\": processed_test_subject1_dict,\n",
    "            \"y_test_subject_1\": y_test_subject_1,\n",
    "            \"x_test_subject_2\": processed_test_subject2_dict,\n",
    "            \"y_test_subject_2\": y_test_subject_2\n",
    "        }\n",
    "        \n",
    "        # Save each dataset as a separate pickle file\n",
    "        for name, data in datasets.items():\n",
    "            save_path = f\"{save_directory}{name}.pkl\"\n",
    "            with open(save_path, 'wb') as file:\n",
    "                pickle.dump(data, file)\n",
    "            print(f\"{name} saved successfully to {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to save datasets: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = load_data(DATA_PATH)\n",
    "    t_df1, t_df2, df = filter_subjects(df)\n",
    "\n",
    "    # Extract labels and convert to numpy arrays\n",
    "    labels_array, validation_labels_array_subject_1, validation_labels_array_subject_2 = extract_labels(df, t_df1, t_df2)\n",
    "\n",
    "    # Pad and reshape metrics\n",
    "    padded_series = pad_and_reshape(df[METRIC], METRIC, MAX_SEQUENCE_LENGTH)\n",
    "    x_test_subject_1_padded = pad_and_reshape(t_df1[METRIC], METRIC, MAX_SEQUENCE_LENGTH)\n",
    "    x_test_subject_2_padded = pad_and_reshape(t_df2[METRIC], METRIC, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    # Ensure padded_series is a DataFrame\n",
    "    print(f\"padded_series shape: {padded_series.shape}, type: {type(padded_series)}\")\n",
    "\n",
    "    # # # Train-test split\n",
    "    x_train, x_val, y_train, y_val = split_train_and_test(padded_series, labels_array, METRIC)   \n",
    "\n",
    "    print(f\"Train shape: {x_train.shape}, Validation shape: {x_val.shape}\")\n",
    "    print(f\"Train labels shape: {y_train.shape}, Validation labels shape: {y_val.shape}\")\n",
    "\n",
    "    # Convert the training and validation labels to DataFrames\n",
    "    y_train_df = pd.DataFrame(y_train, columns=['labels']).astype(np.int32)\n",
    "    y_val_df = pd.DataFrame(y_val, columns=['labels']).astype(np.int32)\n",
    "    y_test_subject_1_df = pd.DataFrame(validation_labels_array_subject_1, columns=['labels']).astype(np.int32)\n",
    "    y_test_subject_2_df = pd.DataFrame(validation_labels_array_subject_2, columns=['labels']).astype(np.int32)\n",
    "\n",
    "    # Apply SMOTE\n",
    "    x_train_resampled, y_train_resampled, x_val_resampled, y_val_resampled= apply_smote(x_train, y_train_df, x_val, y_val_df, METRIC) \n",
    "    print(f\"Train resampled shape: {x_train_resampled.shape}, Validation resampled shape: {x_val_resampled.shape}\")\n",
    "    print(f\"Train resampled labels shape: {y_train_resampled.shape}, Validation resampled labels shape: {y_val_resampled.shape}\")\n",
    "\n",
    "    # Evaluate dataset distribution\n",
    "    plot_dataset_distribution(x_train_resampled, y_train_resampled, x_val_resampled, y_val_resampled, \n",
    "                              x_test_subject_1_padded, y_test_subject_1_df, \n",
    "                              x_test_subject_2_padded, y_test_subject_2_df)\n",
    "\n",
    "    # Save datasets\n",
    "    save_datasets(x_train_resampled, y_train_resampled, x_val_resampled, y_val_resampled, \n",
    "                x_test_subject_1_padded, y_test_subject_1_df, \n",
    "                x_test_subject_2_padded, y_test_subject_2_df)    \n",
    "    \n",
    "    return df, t_df1, t_df2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'file_path' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[91], line 2\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     t_df1, t_df2, df \u001b[38;5;241m=\u001b[39m filter_subjects(df)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Extract labels and convert to numpy arrays\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[80], line 8\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(file_paths, chunk_size, usecols, dtype)\u001b[0m\n\u001b[0;32m      4\u001b[0m total_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(file_paths)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create a thread pool to read files in chunks in parallel\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure only DataFrames are added to the list\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk, _ \u001b[38;5;129;01min\u001b[39;00m read_chunk(\u001b[43mfile_path\u001b[49m, chunk_size, usecols, dtype):\n\u001b[0;32m      9\u001b[0m     dataframes\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'file_path' referenced before assignment"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
