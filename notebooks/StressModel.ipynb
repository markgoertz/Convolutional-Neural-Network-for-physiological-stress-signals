{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.callbacks\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.losses\n",
    "import json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers, callbacks\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, AUC, Precision, Recall, Metric\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model  # Import Model here\n",
    "\n",
    "\n",
    "import dvc.api\n",
    "from dvclive import Live\n",
    "from dvclive.keras import DVCLiveCallback  # Import the callback\n",
    "import yaml\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = os.path.dirname(os.getcwd())\n",
    "DATA_PATH = MAIN_PATH + \"/data/results\"\n",
    "MODEL_PATH = MAIN_PATH + \"/models\"\n",
    "LOG_PATH = MAIN_PATH + \"/logs\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1024\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "BEST_VAL_SCORE = 0\n",
    "BEST_MODEL = None\n",
    "HISTORY = []  # Initialize history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    return dvc.api.params_show(\"params.yaml\")\n",
    "\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_metrics(history_dict: dict):\n",
    "    total_plots = len(history_dict)\n",
    "    cols = total_plots // 2\n",
    "    rows = total_plots // cols\n",
    "    if total_plots % cols != 0:\n",
    "        rows += 1\n",
    "\n",
    "    pos = range(1, total_plots + 1)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (key, value) in enumerate(history_dict.items()):\n",
    "        plt.subplot(rows, cols, pos[i])\n",
    "        plt.plot(range(len(value)), value)\n",
    "        plt.title(str(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df():\n",
    "    df = pd.read_csv(MAIN_PATH + \"/data/result_df.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_missing_values(numpy_data):\n",
    "    numpy_data['x_train'], numpy_data['y_train'] = Remove_missing_values(numpy_data['x_train'], numpy_data['y_train'])\n",
    "    numpy_data['x_val'], numpy_data['y_val'] = Remove_missing_values(numpy_data['x_val'], numpy_data['y_val'])\n",
    "    numpy_data['x_test_1'], numpy_data['y_test_1'] = Remove_missing_values(numpy_data['x_test_1'], numpy_data['y_test_1'])\n",
    "    numpy_data['x_test_2'], numpy_data['y_test_2'] = Remove_missing_values(numpy_data['x_test_2'], numpy_data['y_test_2'])\n",
    "    \n",
    "    return numpy_data\n",
    "\n",
    "def Remove_missing_values(x_data, y_data):\n",
    "    # Check if y_data contains missing values (NaNs) and remove corresponding x_data rows\n",
    "    valid_indices = ~np.isnan(y_data)  # Find valid (non-NaN) indices in y_data\n",
    "    x_clean = x_data[valid_indices]\n",
    "    y_clean = y_data[valid_indices]\n",
    "    return x_clean, y_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_pickle(directory):\n",
    "    \"\"\"\n",
    "    Load all data from pickle files in the specified directory.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Loaded training and test data as dictionaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.pkl'):\n",
    "            key = filename.split('.')[0]  # Use the filename without extension as key\n",
    "            data[key] = pd.read_pickle(os.path.join(directory, filename))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(df, label_column):\n",
    "    vals_dict = {}\n",
    "    for i in df[label_column]:\n",
    "        if i in vals_dict.keys():\n",
    "            vals_dict[i] += 1\n",
    "        else:\n",
    "            vals_dict[i] = 1\n",
    "    total = sum(vals_dict.values())\n",
    "    weight_dict = {k: (1 - (v / total)) for k, v in vals_dict.items()}\n",
    "\n",
    "    print(f\"Weight dict for model: {weight_dict}\")\n",
    "    return weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class F1Score(Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_head(input_layer):\n",
    "    # First convolutional layer\n",
    "    x = tf.keras.layers.Conv1D(filters=32, kernel_size=config[\"model\"][\"kernel_size\"], \n",
    "                      activation=config[\"model\"][\"activation\"], padding=\"same\", \n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(0.001))(input_layer)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    x = tf.keras.layers.Conv1D(64, kernel_size=config[\"model\"][\"kernel_size\"], activation=config[\"model\"][\"activation\"])(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)   \n",
    "    \n",
    "    x = tf.keras.layers.Conv1D(filters=128, kernel_size=config[\"model\"][\"kernel_size\"], \n",
    "                      activation=config[\"model\"][\"activation\"], padding=\"same\", \n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    # Flatten the output\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_layers, model_heads):\n",
    "    # Merge models using their outputs directly\n",
    "    combined = tf.keras.layers.concatenate(model_heads)\n",
    "\n",
    "    # Add additional layers after merging\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(combined)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)  # Adjust based on your task\n",
    "\n",
    "    # Final model\n",
    "    model = keras.Model(inputs=input_layers, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(input_layers, model_heads):\n",
    "    model = build_model(input_layers, model_heads)\n",
    "    optimizer = keras.optimizers.Adam(amsgrad=True, learning_rate=config[\"model\"][\"learning_rate\"])\n",
    "    loss = keras.losses.binary_crossentropy  # Ensure this is a callable, not a result\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "            keras.metrics.AUC(name='auc'),\n",
    "            keras.metrics.Precision(name='precision'),\n",
    "            keras.metrics.Recall(name='recall'),\n",
    "            F1Score(name='f1_score')\n",
    "        ]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, x_val, y_val, class_weight):\n",
    "    \"\"\"Trains the model on the training data.\"\"\"\n",
    "\n",
    "    with Live() as live:\n",
    "        for epoch in range(config['model']['epochs']):\n",
    "            model.fit(\n",
    "                x_train,\n",
    "                y_train,\n",
    "                validation_data=(x_val, y_val),\n",
    "                epochs=1,  # Train for one epoch at a time\n",
    "                class_weight=class_weight,\n",
    "                callbacks=[\n",
    "                    keras.callbacks.ModelCheckpoint(\n",
    "                        filepath=os.path.join(MODEL_PATH, 'best_model.keras'),  # Add filepath argument\n",
    "                        save_best_only=True,\n",
    "                        monitor=\"val_binary_accuracy\"\n",
    "                    ),\n",
    "                    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001),\n",
    "                    DVCLiveCallback(live=live)  # Add DVCLiveCallback to the list\n",
    "                ]\n",
    "            )\n",
    "            live.log_params(config)\n",
    "            live.log_artifact(\n",
    "                os.path.join(MODEL_PATH, 'best_model.h5'),\n",
    "                type=\"model\",\n",
    "                desc=\"This is a convolutional neural network model that is developed to detect stress.\",\n",
    "                labels=[\"no-stress\", \"stress\"],\n",
    "            )\n",
    "\n",
    "        model.save(os.path.join(MODEL_PATH, 'best_model.h5'))\n",
    "        live.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history_to_json(history, fold_number, best_model):\n",
    "    # Create a dictionary for the current fold's metrics\n",
    "    metrics = {\n",
    "        \"fold_number\": fold_number,\n",
    "        \"val_accuracy\": history.history['val_accuracy'][-1],\n",
    "        \"val_loss\": history.history['val_loss'][-1],\n",
    "        \"best_model\": best_model\n",
    "    }\n",
    "\n",
    "    # Load existing metrics if the file exists\n",
    "    if os.path.exists('metrics.json'):\n",
    "        with open('metrics.json', 'r') as f:\n",
    "            existing_metrics = json.load(f)\n",
    "    else:\n",
    "        existing_metrics = []\n",
    "\n",
    "    # Append the new metrics\n",
    "    existing_metrics.append(metrics)\n",
    "\n",
    "    # Write back the updated metrics to the file\n",
    "    with open('metrics.json', 'w') as f:\n",
    "        json.dump(existing_metrics, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preparing_model(x_train, y_train, x_test, y_test, weight_dict):\n",
    "    os.makedirs(MODEL_PATH, exist_ok=True)  # Ensure the model path exists\n",
    "\n",
    "    try:\n",
    "        # Create the model heads\n",
    "        model_heads = []\n",
    "        input_layers = []\n",
    "        \n",
    "        for metric in config['model']['metrics']:\n",
    "            input_shape = (config['model']['input_shapes'][metric], config['model']['input_features'])\n",
    "            input_layer = tf.keras.layers.Input(shape=input_shape, name=f'input_{metric.lower()}')\n",
    "            input_layers.append(input_layer)\n",
    "            print(f\"Input shape for {metric}: {input_shape}\")\n",
    "            \n",
    "            # Create a model head for each input\n",
    "            model_head = create_model_head(input_layer)\n",
    "            model_heads.append(model_head)\n",
    "\n",
    "        print(f\"Model heads created: {model_heads}\")\n",
    "\n",
    "        model = compile_model(input_layers, model_heads)\n",
    "\n",
    "        train_model(\n",
    "            model,\n",
    "            [x_train[metric] for metric in config['model']['metrics']],\n",
    "            y_train,\n",
    "            [x_test[metric] for metric in config['model']['metrics']],\n",
    "            y_test,\n",
    "            weight_dict\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during preparing: {type(e).__name__}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(data, metrics):\n",
    "    filtered_data = {}\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, dict) and key.startswith('x_'):\n",
    "            filtered_data[key] = {k: v for k, v in value.items() if k in metrics}\n",
    "        else:\n",
    "            filtered_data[key] = value\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def main():\n",
    "    df = load_df()\n",
    "    datasets = load_data_from_pickle(DATA_PATH)\n",
    " \n",
    "    # Extract the datasets\n",
    "    x_train = datasets['x_train']\n",
    "    y_train = datasets['y_train']\n",
    "\n",
    "    x_val = datasets['x_val']\n",
    "    y_val = datasets['y_val']\n",
    "\n",
    "    # Calculate weights\n",
    "    weight_dict = calculate_class_weights(df, 'downsampled_label')\n",
    "\n",
    "    # Filter columns based on config['model']['metrics']\n",
    "    datasets = filter_columns(datasets, config['model']['metrics'])\n",
    "\n",
    "    for key, value in datasets.items():\n",
    "        if isinstance(value, dict):\n",
    "            for sub_key, sub_value in value.items():\n",
    "                print(f\"Shape of {key}_{sub_key}: {sub_value.shape}\")\n",
    "        else:\n",
    "            print(f\"Shape of {key}: {value.shape}\")\n",
    "\n",
    "    # Train model\n",
    "    x = Preparing_model(x_train, y_train, x_val, y_val, weight_dict)\n",
    "    print(f\"Model training completed\")\n",
    "\n",
    "    return y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight dict for model: {0: 0.11450662739322537, 1: 0.8854933726067746}\n",
      "Shape of x_test_1: (703, 6)\n",
      "Shape of x_test_2: (740, 6)\n",
      "Shape of x_train_EDA: (13326, 32, 1)\n",
      "Shape of x_train_BVP: (13326, 256, 1)\n",
      "Shape of x_train_TEMP: (13326, 32, 1)\n",
      "Shape of x_val_EDA: (3348, 32, 1)\n",
      "Shape of x_val_BVP: (3348, 256, 1)\n",
      "Shape of x_val_TEMP: (3348, 32, 1)\n",
      "Shape of y_test_1: (703,)\n",
      "Shape of y_test_2: (740,)\n",
      "Shape of y_train: (13326,)\n",
      "Shape of y_val: (3348,)\n",
      "Input shape for EDA: (32, 1)\n",
      "Input shape for BVP: (256, 1)\n",
      "Input shape for TEMP: (32, 1)\n",
      "Model heads created: [<KerasTensor: shape=(None, 384) dtype=float32 (created by layer 'flatten')>, <KerasTensor: shape=(None, 3968) dtype=float32 (created by layer 'flatten_1')>, <KerasTensor: shape=(None, 384) dtype=float32 (created by layer 'flatten_2')>]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_eda (InputLayer)         [(None, 32, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " input_bvp (InputLayer)         [(None, 256, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " input_temp (InputLayer)        [(None, 32, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 32, 32)       128         ['input_eda[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 256, 32)      128         ['input_bvp[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 32, 32)       128         ['input_temp[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32)      128         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 256, 32)     128         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32)      128         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 16, 32)       0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 128, 32)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 16, 32)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 14, 64)       6208        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 126, 64)      6208        ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 14, 64)       6208        ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 64)      256         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 126, 64)     256         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 14, 64)      256         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 7, 64)       0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 63, 64)      0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 7, 64)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 7, 128)       24704       ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 63, 128)      24704       ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 7, 128)       24704       ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 7, 128)      512         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 63, 128)     512         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 7, 128)      512         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 3, 128)      0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 31, 128)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 3, 128)      0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 384)          0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 3968)         0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 384)          0           ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4736)         0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          606336      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            65          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 710,465\n",
      "Trainable params: 709,121\n",
      "Non-trainable params: 1,344\n",
      "__________________________________________________________________________________________________\n",
      "417/417 [==============================] - ETA: 0s - loss: 0.2161 - binary_accuracy: 0.8480 - auc: 0.9286 - precision: 0.7726 - recall: 0.9865 - f1_score: 0.8665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:2319: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 35s 45ms/step - loss: 0.2161 - binary_accuracy: 0.8480 - auc: 0.9286 - precision: 0.7726 - recall: 0.9865 - f1_score: 0.8665 - val_loss: 0.6723 - val_binary_accuracy: 0.6965 - val_auc: 0.9343 - val_precision: 0.6223 - val_recall: 1.0000 - val_f1_score: 0.7672 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\output.py:1360\u001b[0m, in \u001b[0;36mOutput.add\u001b[1;34m(self, path, no_commit, relink)\u001b[0m\n\u001b[0;32m   1359\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhash_name\n\u001b[1;32m-> 1360\u001b[0m     staging, meta, obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdvcignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\output.py:547\u001b[0m, in \u001b[0;36mOutput._build\u001b[1;34m(self, no_progress_bar, *args, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchecksum_jobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mhash_jobs)\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m build(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc_data\\hashfile\\build.py:407\u001b[0m, in \u001b[0;36mbuild\u001b[1;34m(odb, path, fs, name, upload, dry_run, ignore, callback, checksum_jobs, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# assert protocol(path) == fs.protocol\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m details \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m staging \u001b[38;5;241m=\u001b[39m _get_staging(odb)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc_objects\\fs\\base.py:592\u001b[0m, in \u001b[0;36mFileSystem.info\u001b[1;34m(self, path, callback, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39minfo(path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    593\u001b[0m callback\u001b[38;5;241m.\u001b[39mset_size(\u001b[38;5;28mlen\u001b[39m(path))\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc_objects\\fs\\local.py:39\u001b[0m, in \u001b[0;36mFsspecLocalFileSystem.info\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\fsspec\\implementations\\local.py:94\u001b[0m, in \u001b[0;36mLocalFileSystem.info\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m---> 94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m link \u001b[38;5;241m=\u001b[39m stat\u001b[38;5;241m.\u001b[39mS_ISLNK(out\u001b[38;5;241m.\u001b[39mst_mode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'c:/Master of Applied IT/models/best_model.h5'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOutputDoesNotExistError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvclive\\utils.py:182\u001b[0m, in \u001b[0;36mcatch_and_warn.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvclive\\live.py:842\u001b[0m, in \u001b[0;36mLive.cache\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    837\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    838\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo track \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m automatically in the DVC pipeline, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd it as an output of the pipeline stage.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         )\n\u001b[1;32m--> 842\u001b[0m stage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dvc_repo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m dvc_file \u001b[38;5;241m=\u001b[39m stage[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39maddressing\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\repo\\__init__.py:58\u001b[0m, in \u001b[0;36mlocked.<locals>.wrapper\u001b[1;34m(repo, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m lock_repo(repo):\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(repo, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\repo\\scm_context.py:143\u001b[0m, in \u001b[0;36mscm_context.<locals>.run\u001b[1;34m(repo, *args, **kw)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mscm_context(autostage\u001b[38;5;241m=\u001b[39mautostage, quiet\u001b[38;5;241m=\u001b[39mquiet):\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m method(repo, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\repo\\add.py:233\u001b[0m, in \u001b[0;36madd\u001b[1;34m(repo, targets, no_commit, glob, out, remote, to_remote, remote_jobs, force, relink)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 233\u001b[0m     \u001b[43m_add\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_exists\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_commit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_commit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CacheLinkError:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\repo\\add.py:183\u001b[0m, in \u001b[0;36m_add\u001b[1;34m(stage, source, no_commit, relink)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     \u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_outs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_commit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_commit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelink\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CacheLinkError:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\funcy\\decorators.py:47\u001b[0m, in \u001b[0;36mmake_decorator.<locals>._decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m call \u001b[38;5;241m=\u001b[39m Call(func, args, kwargs)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m deco(call, \u001b[38;5;241m*\u001b[39mdargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdkwargs)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\stage\\decorators.py:44\u001b[0m, in \u001b[0;36mrwlocked\u001b[1;34m(call, read, write)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rwlock(\n\u001b[0;32m     37\u001b[0m     stage\u001b[38;5;241m.\u001b[39mrepo\u001b[38;5;241m.\u001b[39mtmp_dir,\n\u001b[0;32m     38\u001b[0m     stage\u001b[38;5;241m.\u001b[39mrepo\u001b[38;5;241m.\u001b[39mfs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     stage\u001b[38;5;241m.\u001b[39mrepo\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhardlink_lock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     43\u001b[0m ):\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\funcy\\decorators.py:68\u001b[0m, in \u001b[0;36mCall.__call__\u001b[1;34m(self, *a, **kw)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m a \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw:\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\stage\\__init__.py:585\u001b[0m, in \u001b[0;36mStage.add_outs\u001b[1;34m(self, filter_info, allow_missing, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m     out\u001b[38;5;241m.\u001b[39madd(filter_info, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mFileNotFoundError\u001b[39;00m, OutputDoesNotExistError):\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\output.py:1370\u001b[0m, in \u001b[0;36mOutput.add\u001b[1;34m(self, path, no_commit, relink)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexists:\n\u001b[1;32m-> 1370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDoesNotExistError(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_dir_checksum:\n",
      "\u001b[1;31mOutputDoesNotExistError\u001b[0m: output '..\\models\\best_model.h5' does not exist",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\logging\\__init__.py:1086\u001b[0m, in \u001b[0;36mStreamHandler.emit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;66;03m# issue 35046: merged two stream.writes into one.\u001b[39;00m\n\u001b[1;32m-> 1086\u001b[0m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py:47\u001b[0m, in \u001b[0;36mStreamWrapper.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convertor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py:177\u001b[0m, in \u001b[0;36mAnsiToWin32.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert:\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py:205\u001b[0m, in \u001b[0;36mAnsiToWin32.write_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    204\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m end\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_plain_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py:210\u001b[0m, in \u001b[0;36mAnsiToWin32.write_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m<\u001b[39m end:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py:679\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    678\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI/O operation on closed file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    681\u001b[0m is_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_master_process()\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 23\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, x_train, y_train, x_val, y_val, class_weight)\u001b[0m\n\u001b[0;32m     22\u001b[0m     live\u001b[38;5;241m.\u001b[39mlog_params(config)\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mlive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThis is a convolutional neural network model that is developed to detect stress.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno-stress\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstress\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MODEL_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvclive\\live.py:794\u001b[0m, in \u001b[0;36mLive.log_artifact\u001b[1;34m(self, path, type, name, desc, labels, meta, copy, cache)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache:\n\u001b[1;32m--> 794\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m((\u001b[38;5;28mtype\u001b[39m, name, desc, labels, meta)):\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvclive\\utils.py:184\u001b[0m, in \u001b[0;36mcatch_and_warn.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError in \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43me\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\logging\\__init__.py:1458\u001b[0m, in \u001b[0;36mLogger.warning\u001b[1;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misEnabledFor(WARNING):\n\u001b[1;32m-> 1458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log(WARNING, msg, args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\logging\\__init__.py:1589\u001b[0m, in \u001b[0;36mLogger._log\u001b[1;34m(self, level, msg, args, exc_info, extra, stack_info, stacklevel)\u001b[0m\n\u001b[0;32m   1587\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakeRecord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, level, fn, lno, msg, args,\n\u001b[0;32m   1588\u001b[0m                          exc_info, func, extra, sinfo)\n\u001b[1;32m-> 1589\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\logging\\__init__.py:1599\u001b[0m, in \u001b[0;36mLogger.handle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisabled) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter(record):\n\u001b[1;32m-> 1599\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallHandlers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\logging\\__init__.py:1661\u001b[0m, in \u001b[0;36mLogger.callHandlers\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record\u001b[38;5;241m.\u001b[39mlevelno \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m hdlr\u001b[38;5;241m.\u001b[39mlevel:\n\u001b[1;32m-> 1661\u001b[0m         \u001b[43mhdlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m c\u001b[38;5;241m.\u001b[39mpropagate:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\logging\\__init__.py:952\u001b[0m, in \u001b[0;36mHandler.handle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 952\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\logging\\__init__.py:1091\u001b[0m, in \u001b[0;36mStreamHandler.emit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m-> 1091\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandleError\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\logging\\__init__.py:1004\u001b[0m, in \u001b[0;36mHandler.handleError\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1004\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--- Logging error ---\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exception(t, v, tb, \u001b[38;5;28;01mNone\u001b[39;00m, sys\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py:47\u001b[0m, in \u001b[0;36mStreamWrapper.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convertor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py:177\u001b[0m, in \u001b[0;36mAnsiToWin32.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert:\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py:205\u001b[0m, in \u001b[0;36mAnsiToWin32.write_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    204\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m end\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_plain_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py:210\u001b[0m, in \u001b[0;36mAnsiToWin32.write_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m<\u001b[39m end:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py:679\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    678\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI/O operation on closed file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    681\u001b[0m is_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_master_process()\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m x\n",
      "Cell \u001b[1;32mIn[61], line 28\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mPreparing_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_val\n",
      "Cell \u001b[1;32mIn[59], line 23\u001b[0m, in \u001b[0;36mPreparing_model\u001b[1;34m(x_train, y_train, x_test, y_test, weight_dict)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel heads created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     model \u001b[38;5;241m=\u001b[39m compile_model(input_layers, model_heads)\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_dict\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred during preparing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[57], line 31\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, x_train, y_train, x_val, y_val, class_weight)\u001b[0m\n\u001b[0;32m     23\u001b[0m     live\u001b[38;5;241m.\u001b[39mlog_artifact(\n\u001b[0;32m     24\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MODEL_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m         desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a convolutional neural network model that is developed to detect stress.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m         labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno-stress\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstress\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     28\u001b[0m     )\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MODEL_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 31\u001b[0m live\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvclive\\live.py:978\u001b[0m, in \u001b[0;36mLive.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inside_with \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvclive\\live.py:953\u001b[0m, in \u001b[0;36mLive.end\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dvcyaml:\n\u001b[0;32m    949\u001b[0m         catch_and_warn(DvcException, logger)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dvc_repo\u001b[38;5;241m.\u001b[39mscm\u001b[38;5;241m.\u001b[39madd)(\n\u001b[0;32m    950\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdvc_file\n\u001b[0;32m    951\u001b[0m         )\n\u001b[1;32m--> 953\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dvc_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_studio_updates_posted()\n\u001b[0;32m    957\u001b[0m \u001b[38;5;66;03m# Mark experiment as done\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvclive\\utils.py:182\u001b[0m, in \u001b[0;36mcatch_and_warn.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    184\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvclive\\live.py:985\u001b[0m, in \u001b[0;36mLive.save_dvc_exp\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dvcyaml:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_include_untracked\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdvc_file)\n\u001b[1;32m--> 985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_rev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dvc_repo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exp_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_untracked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_include_untracked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exp_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\repo\\experiments\\__init__.py:359\u001b[0m, in \u001b[0;36mExperiments.save\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdvc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrepo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msave\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\repo\\experiments\\save.py:36\u001b[0m, in \u001b[0;36msave\u001b[1;34m(repo, targets, name, recursive, force, include_untracked, message)\u001b[0m\n\u001b[0;32m     33\u001b[0m executor \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39minit_executor(repo\u001b[38;5;241m.\u001b[39mexperiments, entry)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     save_result \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecursive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_untracked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_untracked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     result \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39mcollect_executor(repo\u001b[38;5;241m.\u001b[39mexperiments, executor, save_result)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\repo\\experiments\\executor\\base.py:303\u001b[0m, in \u001b[0;36mBaseExecutor.save\u001b[1;34m(cls, info, targets, recursive, force, include_untracked, message)\u001b[0m\n\u001b[0;32m    300\u001b[0m     dvc\u001b[38;5;241m.\u001b[39mscm\u001b[38;5;241m.\u001b[39madd(include_untracked, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mauto_push(dvc):\n\u001b[1;32m--> 303\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdvc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m ref: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m dvc\u001b[38;5;241m.\u001b[39mscm\u001b[38;5;241m.\u001b[39mget_ref(EXEC_BRANCH, follow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    312\u001b[0m exp_ref \u001b[38;5;241m=\u001b[39m ExpRefInfo\u001b[38;5;241m.\u001b[39mfrom_ref(ref) \u001b[38;5;28;01mif\u001b[39;00m ref \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dvc\\repo\\experiments\\executor\\base.py:766\u001b[0m, in \u001b[0;36mBaseExecutor.commit\u001b[1;34m(cls, scm, exp_hash, exp_name, force, message)\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommit to new experiment branch \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, branch)\n\u001b[1;32m--> 766\u001b[0m \u001b[43mscm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m message \u001b[38;5;241m=\u001b[39m message \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdvc: commit experiment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    768\u001b[0m scm\u001b[38;5;241m.\u001b[39mcommit(message, no_verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\scmrepo\\git\\__init__.py:307\u001b[0m, in \u001b[0;36mGit._backend_func\u001b[1;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackends[key]\n\u001b[0;32m    306\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(backend, name)\n\u001b[1;32m--> 307\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_backend \u001b[38;5;241m=\u001b[39m key\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmove_to_end(key, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\scmrepo\\git\\backend\\dulwich\\__init__.py:328\u001b[0m, in \u001b[0;36mDulwichBackend.add\u001b[1;34m(self, paths, update, force)\u001b[0m\n\u001b[0;32m    325\u001b[0m paths \u001b[38;5;241m=\u001b[39m [paths] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(paths, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(paths)\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m update \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths:\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    331\u001b[0m files: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    332\u001b[0m     os\u001b[38;5;241m.\u001b[39mfsencode(fpath) \u001b[38;5;28;01mfor\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_paths(paths, force\u001b[38;5;241m=\u001b[39mforce)\n\u001b[0;32m    333\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dulwich\\repo.py:1439\u001b[0m, in \u001b[0;36mRepo.stage\u001b[1;34m(self, fs_paths)\u001b[0m\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1438\u001b[0m     blob \u001b[38;5;241m=\u001b[39m blob_from_path_and_stat(full_path, st)\n\u001b[1;32m-> 1439\u001b[0m     blob \u001b[38;5;241m=\u001b[39m \u001b[43mblob_normalizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckin_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobject_store\u001b[38;5;241m.\u001b[39madd_object(blob)\n\u001b[0;32m   1441\u001b[0m     index[tree_path] \u001b[38;5;241m=\u001b[39m index_entry_from_stat(st, blob\u001b[38;5;241m.\u001b[39mid)\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dulwich\\line_ending.py:303\u001b[0m, in \u001b[0;36mTreeBlobNormalizer.checkin_normalize\u001b[1;34m(self, blob, tree_path)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheckin_normalize\u001b[39m(\u001b[38;5;28mself\u001b[39m, blob, tree_path):\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;66;03m# Existing files should only be normalized on checkin if it was\u001b[39;00m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;66;03m# previously normalized on checkout\u001b[39;00m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfallback_read_filter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m tree_path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexisting_paths\n\u001b[0;32m    302\u001b[0m     ):\n\u001b[1;32m--> 303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckin_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m blob\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dulwich\\line_ending.py:246\u001b[0m, in \u001b[0;36mBlobNormalizer.checkin_normalize\u001b[1;34m(self, blob, tree_path)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Normalize a blob during a checkin operation.\"\"\"\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfallback_write_filter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnormalize_blob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfallback_write_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blob\n",
      "File \u001b[1;32mc:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\dulwich\\line_ending.py:278\u001b[0m, in \u001b[0;36mnormalize_blob\u001b[1;34m(blob, conversion, binary_detection)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m blob\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Now apply the conversion\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m converted_data \u001b[38;5;241m=\u001b[39m \u001b[43mconversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m new_blob \u001b[38;5;241m=\u001b[39m Blob()\n\u001b[0;32m    281\u001b[0m new_blob\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m converted_data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = main()\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
