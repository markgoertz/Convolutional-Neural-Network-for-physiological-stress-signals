{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers, callbacks\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, AUC, Precision, Recall, Metric\n",
    "from numpy import mean, std\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = os.path.dirname(os.getcwd())\n",
    "DATA_PATH = MAIN_PATH + \"/data/numpy\"\n",
    "MODEL_PATH = MAIN_PATH + \"/models\"\n",
    "LOG_PATH = MAIN_PATH + \"/logs\"\n",
    "\n",
    "BEST_VAL_SCORE = 0\n",
    "BEST_MODEL = None\n",
    "HISTORY = []  # Initialize history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "global config\n",
    "config = load_config('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_metrics(history_dict: dict):\n",
    "    total_plots = len(history_dict)\n",
    "    cols = total_plots // 2\n",
    "    rows = total_plots // cols\n",
    "    if total_plots % cols != 0:\n",
    "        rows += 1\n",
    "\n",
    "    pos = range(1, total_plots + 1)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (key, value) in enumerate(history_dict.items()):\n",
    "        plt.subplot(rows, cols, pos[i])\n",
    "        plt.plot(range(len(value)), value)\n",
    "        plt.title(str(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df():\n",
    "    df = pd.read_csv(MAIN_PATH + \"/data/result_df.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_missing_values(numpy_data):\n",
    "    numpy_data['x_train'], numpy_data['y_train'] = Remove_missing_values(numpy_data['x_train'], numpy_data['y_train'])\n",
    "    numpy_data['x_val'], numpy_data['y_val'] = Remove_missing_values(numpy_data['x_val'], numpy_data['y_val'])\n",
    "    numpy_data['x_test_1'], numpy_data['y_test_1'] = Remove_missing_values(numpy_data['x_test_1'], numpy_data['y_test_1'])\n",
    "    numpy_data['x_test_2'], numpy_data['y_test_2'] = Remove_missing_values(numpy_data['x_test_2'], numpy_data['y_test_2'])\n",
    "    \n",
    "    return numpy_data\n",
    "\n",
    "def Remove_missing_values(x_data, y_data):\n",
    "    # Check if y_data contains missing values (NaNs) and remove corresponding x_data rows\n",
    "    valid_indices = ~np.isnan(y_data)  # Find valid (non-NaN) indices in y_data\n",
    "    x_clean = x_data[valid_indices]\n",
    "    y_clean = y_data[valid_indices]\n",
    "    return x_clean, y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_numpy_files(data_path):\n",
    "    numpy_data = {}\n",
    "    \n",
    "    for file_name in os.listdir(data_path):\n",
    "        if file_name.endswith('.npy'):\n",
    "            file_path = os.path.join(data_path, file_name)\n",
    "            numpy_data[file_name[:-4]] = np.load(file_path)  # Store in dict\n",
    "    \n",
    "    # Clean data by removing rows where y_* contains missing values\n",
    "    numpy_data = Clean_missing_values(numpy_data)\n",
    "\n",
    "    return numpy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(df, label_column):\n",
    "    vals_dict = {}\n",
    "    for i in df[label_column]:\n",
    "        if i in vals_dict.keys():\n",
    "            vals_dict[i] += 1\n",
    "        else:\n",
    "            vals_dict[i] = 1\n",
    "    total = sum(vals_dict.values())\n",
    "    weight_dict = {k: (1 - (v / total)) for k, v in vals_dict.items()}\n",
    "\n",
    "    print(f\"Weight dict for model: {weight_dict}\")\n",
    "    return weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(given_kernel_size):\n",
    "    input_layer = keras.Input(shape=(config['input_shape'], config['input_features']))\n",
    "    \n",
    "    x = layers.Conv1D(filters=32, kernel_size=given_kernel_size, activation=config['activation'], padding=\"same\", kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters=64, kernel_size=given_kernel_size, activation=config['activation'], padding=\"same\", kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters=128, kernel_size=given_kernel_size, activation=config['activation'], padding=\"same\", kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation=config['activation'], kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(256, activation=config['activation'], kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compile_model(kernel_size):\n",
    "    model = create_model(kernel_size)\n",
    "    optimizer = keras.optimizers.Adam(amsgrad=True, learning_rate=config['learning_rate'])\n",
    "    loss = keras.losses.BinaryCrossentropy()\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "            keras.metrics.AUC(name='auc'),\n",
    "            keras.metrics.Precision(name='precision'),\n",
    "            keras.metrics.Recall(name='recall'),\n",
    "            F1Score(name='f1_score')\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitDatasetForFolds(train_index, validation_index, fold_nr, numpy_data):\n",
    "    print(f\"Training fold {fold_nr}...\")\n",
    "\n",
    "    # Split the data into train sets for this fold.\n",
    "    x_train_fold = numpy_data['x_train'][train_index]\n",
    "    y_train_fold = numpy_data['y_train'][train_index]\n",
    "\n",
    "    print(f\"x_val shape: {numpy_data['x_val'].shape}\")\n",
    "    print(f\"y_val shape: {numpy_data['y_val'].shape}\")\n",
    "    \n",
    "    # Ensure to use only the training set indices\n",
    "    x_validation_fold = numpy_data['x_val'][:len(validation_index)]  # Taking the first `len(validation_index)` samples\n",
    "    y_validation_fold = numpy_data['y_val'][:len(validation_index)]\n",
    "\n",
    "    # Create tf.data.Datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train_fold, y_train_fold))\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices((x_validation_fold, y_validation_fold))\n",
    "    test_dataset_subject1 = tf.data.Dataset.from_tensor_slices((numpy_data['x_test_1'], numpy_data['y_test_1']))\t\n",
    "    test_dataset_subject2 = tf.data.Dataset.from_tensor_slices((numpy_data['x_test_2'], numpy_data['y_test_2']))\n",
    "    \n",
    "    # Shuffling and batching the datasets\n",
    "    train_dataset = train_dataset.shuffle(config['shuffle_buffer_size']).batch(config['batch_size'])\n",
    "    validation_dataset = validation_dataset.shuffle(config['shuffle_buffer_size']).batch(config['batch_size'])\n",
    "    test_dataset_subject1 = test_dataset_subject1.batch(config['batch_size'])\n",
    "    test_dataset_subject2 = test_dataset_subject2.batch(config['batch_size'])\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset_subject1, test_dataset_subject2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_native(data):\n",
    "    \"\"\"Recursively convert numpy types to native python types.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {key: convert_to_native(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_to_native(item) for item in data]\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return data.tolist()  # Convert numpy array to list\n",
    "    elif isinstance(data, (np.float32, np.float64)):\n",
    "        return data.item()  # Convert single value numpy float to Python float\n",
    "    else:\n",
    "        return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history_to_json(history, fold_number, best_model):\n",
    "    \"\"\"Save the training history and best model path to a JSON file.\"\"\"\n",
    "    try:\n",
    "        history_data = {\n",
    "            \"history\": convert_to_native(history.history),\n",
    "            \"best_model\": best_model\n",
    "        }\n",
    "        \n",
    "        history_file_path = os.path.join(LOG_PATH, f\"history_fold_{fold_number}.json\")\n",
    "        with open(history_file_path, 'w') as json_file:\n",
    "            json.dump(history_data, json_file)  # Write the history and best model to a JSON file\n",
    "        print(f\"History and best model saved to {history_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving history: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvclive.keras import DVCLiveCallback\n",
    "\n",
    "def Train_fold(train_index, val_index, fold_number, numpy_data, weight_dict, kernel_size):\n",
    "    global BEST_VAL_SCORE, HISTORY \n",
    "\n",
    "    # Split data into training and validation sets for this fold\n",
    "    train_dataset, validation_dataset, test_sj1, test_sj2 = SplitDatasetForFolds(train_index, val_index, fold_number, numpy_data)\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = Compile_model(kernel_size)\n",
    "    model.summary()\n",
    "\n",
    "    # Set up DVC Live callback for this fold\n",
    "    live_callback = DVCLiveCallback()\n",
    "\n",
    "    # Set up other callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(MODEL_PATH, f\"best_model_fold_{fold_number}.keras\"),\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_accuracy\"\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001),\n",
    "        live_callback\n",
    "    ]\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=config['epochs'],\n",
    "        validation_data=validation_dataset,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=weight_dict\n",
    "    )\n",
    "\n",
    "    fold_performance = model.evaluate(validation_dataset, batch_size=config['batch_size'], verbose=0)\n",
    "    print(f\"Train accuracy for fold {fold_number}: {fold_performance[1]}\")\n",
    "\n",
    "    return fold_performance[1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvclive import Live\n",
    "\n",
    "def Cross_validation_training(numpy_data, weight_dict, kernel_size):\n",
    "    global fold_number\n",
    "    fold_number = 1\n",
    "    scores = list()\n",
    "\n",
    "    os.makedirs(MODEL_PATH, exist_ok=True)  # Ensure the model path exists\n",
    "    # Initialize KFold with the number of splits\n",
    "    kfold = KFold(n_splits=config['folds'], shuffle=True, random_state=42)\n",
    "\n",
    "    try:\n",
    "        for train_index, val_index in kfold.split(numpy_data['x_train']):\n",
    "            print(f\"Training fold {fold_number}\")\n",
    "\n",
    "            # Start a new DVCLive run for this fold\n",
    "            live = Live()  \n",
    "\n",
    "            # Train the current fold, ensuring kernel_size is passed\n",
    "            score = Train_fold(train_index, val_index, fold_number, numpy_data, weight_dict, kernel_size)\n",
    "        \n",
    "            score = score * 100.0\n",
    "            print('>p=%d #%d: %.3f' % (kernel_size, fold_number, score))\n",
    "            scores.append(score)\n",
    "\n",
    "            fold_number += 1\n",
    "        \n",
    "        live.end()  # End the DVCLive run for logging the final average score\n",
    "\n",
    "        return scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during cross-validation training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores, params):\n",
    "\tprint(scores, params)\n",
    "\t# summarize mean and standard deviation\n",
    "\tfor i in range(len(scores)):\n",
    "\t\tm, s = mean(scores[i]), std(scores[i])\n",
    "\t\tprint('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "\t# boxplot of scores\n",
    "\tplt.boxplot(scores, labels=params)\n",
    "\tplt.xlabel('Kernel Size')\n",
    "\tplt.ylabel('Score')\n",
    "\tplt.title('Model Performance by Kernel Size')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        df = load_df()\n",
    "        numpy_data = gather_numpy_files(DATA_PATH)\n",
    "\n",
    "        # test each parameter\n",
    "        all_scores = list()\n",
    "\n",
    "        # Calculate weights\n",
    "        weight_dict = calculate_class_weights(df, 'downsampled_label')\n",
    "        for kernel_size in config['kernel_sizes']:\n",
    "            print(f\"Running model with kernel size: {kernel_size}\")\n",
    "            # Train model\n",
    "            scores = Cross_validation_training(numpy_data, weight_dict, kernel_size)\n",
    "            all_scores.append(scores)\n",
    "        # summarize results\n",
    "\n",
    "        print(\"Cross-validation training completed.\\n\")\n",
    "\n",
    "        return all_scores\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in main: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight dict for model: {0: 0.11450662739322537, 1: 0.8854933726067746}\n",
      "Running model with kernel size: 3\n",
      "Training fold 1\n",
      "Training fold 1...\n",
      "x_val shape: (4988, 32, 1)\n",
      "y_val shape: (4988,)\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 32, 1)]           0         \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, 32, 32)            128       \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 32, 32)           128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPoolin  (None, 16, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 16, 64)            6208      \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 16, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (None, 8, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 8, 128)            24704     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 8, 128)           512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_26 (MaxPoolin  (None, 4, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 426,177\n",
      "Trainable params: 425,729\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Starting training...\n",
      "Epoch 1/5\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.9206 - binary_accuracy: 0.7607 - auc: 0.8991 - precision: 0.6912 - recall: 0.9423 - f1_score: 0.7975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:2319: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 9s 35ms/step - loss: 0.9181 - binary_accuracy: 0.7625 - auc: 0.8995 - precision: 0.6948 - recall: 0.9435 - f1_score: 0.8003 - val_loss: 2.6396 - val_binary_accuracy: 0.5000 - val_auc: 0.5667 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1_score: 0.6667 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.6084 - binary_accuracy: 0.7717 - auc: 0.9154 - precision: 0.6976 - recall: 0.9661 - f1_score: 0.8102WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 7s 37ms/step - loss: 0.6084 - binary_accuracy: 0.7717 - auc: 0.9154 - precision: 0.6976 - recall: 0.9661 - f1_score: 0.8102 - val_loss: 2.5430 - val_binary_accuracy: 0.5000 - val_auc: 0.7349 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1_score: 0.6667 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.4191 - binary_accuracy: 0.7712 - auc: 0.9217 - precision: 0.6957 - recall: 0.9712 - f1_score: 0.8107WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.4191 - binary_accuracy: 0.7712 - auc: 0.9217 - precision: 0.6957 - recall: 0.9712 - f1_score: 0.8107 - val_loss: 2.0541 - val_binary_accuracy: 0.5154 - val_auc: 0.8122 - val_precision: 0.5078 - val_recall: 0.9992 - val_f1_score: 0.6734 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.3042 - binary_accuracy: 0.7715 - auc: 0.9242 - precision: 0.6941 - recall: 0.9740 - f1_score: 0.8106WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 7s 37ms/step - loss: 0.3038 - binary_accuracy: 0.7724 - auc: 0.9243 - precision: 0.6960 - recall: 0.9743 - f1_score: 0.8120 - val_loss: 2.5868 - val_binary_accuracy: 0.5060 - val_auc: 0.7223 - val_precision: 0.5030 - val_recall: 1.0000 - val_f1_score: 0.6694 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.2389 - binary_accuracy: 0.7596 - auc: 0.9251 - precision: 0.6825 - recall: 0.9787 - f1_score: 0.8042WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.2389 - binary_accuracy: 0.7596 - auc: 0.9251 - precision: 0.6825 - recall: 0.9787 - f1_score: 0.8042 - val_loss: 1.9060 - val_binary_accuracy: 0.5698 - val_auc: 0.7963 - val_precision: 0.5377 - val_recall: 0.9960 - val_f1_score: 0.6983 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to validate remotes. Disabling auto push: config file error: no remote specified in d:\\Master of Applied IT. Create a default remote with\n",
      "    dvc remote add -d <remote name> <remote url>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for fold 1: 0.5712090134620667\n",
      ">p=3 #1: 57.121\n",
      "Training fold 2\n",
      "Training fold 2...\n",
      "x_val shape: (4988, 32, 1)\n",
      "y_val shape: (4988,)\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 32, 1)]           0         \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 32, 32)            128       \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 32, 32)           128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_27 (MaxPoolin  (None, 16, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_28 (Conv1D)          (None, 16, 64)            6208      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 16, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPoolin  (None, 8, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 8, 128)            24704     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 8, 128)           512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (None, 4, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 426,177\n",
      "Trainable params: 425,729\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Starting training...\n",
      "Epoch 1/5\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.9283 - binary_accuracy: 0.7339 - auc: 0.8897 - precision: 0.6603 - recall: 0.9426 - f1_score: 0.7766WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 10s 35ms/step - loss: 0.9256 - binary_accuracy: 0.7363 - auc: 0.8906 - precision: 0.6648 - recall: 0.9438 - f1_score: 0.7801 - val_loss: 2.3788 - val_binary_accuracy: 0.5000 - val_auc: 0.6283 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1_score: 0.6667 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.6199 - binary_accuracy: 0.7436 - auc: 0.9054 - precision: 0.6659 - recall: 0.9642 - f1_score: 0.7878WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.6191 - binary_accuracy: 0.7445 - auc: 0.9054 - precision: 0.6677 - recall: 0.9645 - f1_score: 0.7891 - val_loss: 2.2238 - val_binary_accuracy: 0.5000 - val_auc: 0.7610 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1_score: 0.6667 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.4286 - binary_accuracy: 0.7531 - auc: 0.9176 - precision: 0.6723 - recall: 0.9742 - f1_score: 0.7956WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 7s 37ms/step - loss: 0.4281 - binary_accuracy: 0.7541 - auc: 0.9175 - precision: 0.6743 - recall: 0.9745 - f1_score: 0.7971 - val_loss: 1.8452 - val_binary_accuracy: 0.5347 - val_auc: 0.7911 - val_precision: 0.5180 - val_recall: 0.9992 - val_f1_score: 0.6823 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.3116 - binary_accuracy: 0.7399 - auc: 0.9223 - precision: 0.6606 - recall: 0.9773 - f1_score: 0.7883WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 7s 37ms/step - loss: 0.3116 - binary_accuracy: 0.7399 - auc: 0.9223 - precision: 0.6606 - recall: 0.9773 - f1_score: 0.7883 - val_loss: 1.9482 - val_binary_accuracy: 0.5880 - val_auc: 0.7873 - val_precision: 0.5486 - val_recall: 0.9936 - val_f1_score: 0.7069 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.2481 - binary_accuracy: 0.7443 - auc: 0.9179 - precision: 0.6631 - recall: 0.9788 - f1_score: 0.7906WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 7s 37ms/step - loss: 0.2477 - binary_accuracy: 0.7454 - auc: 0.9179 - precision: 0.6652 - recall: 0.9790 - f1_score: 0.7921 - val_loss: 1.5638 - val_binary_accuracy: 0.5880 - val_auc: 0.7943 - val_precision: 0.5485 - val_recall: 0.9948 - val_f1_score: 0.7071 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to validate remotes. Disabling auto push: config file error: no remote specified in d:\\Master of Applied IT. Create a default remote with\n",
      "    dvc remote add -d <remote name> <remote url>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for fold 2: 0.5852117538452148\n",
      ">p=3 #2: 58.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to validate remotes. Disabling auto push: config file error: no remote specified in d:\\Master of Applied IT. Create a default remote with\n",
      "    dvc remote add -d <remote name> <remote url>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation training completed.\n",
      "\n",
      "[[57.120901346206665, 58.521175384521484]] [3]\n",
      "Param=3: 57.821% (+/-0.700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goert\\AppData\\Local\\Temp\\ipykernel_23312\\821211489.py:9: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(scores, labels=params)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_scores = main()\n",
    "\n",
    "summarize_results(all_scores, config['kernel_sizes'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
