{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers, callbacks\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, AUC, Precision, Recall, Metric\n",
    "from numpy import mean, std\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = os.path.dirname(os.getcwd())\n",
    "DATA_PATH = MAIN_PATH + \"/data/numpy\"\n",
    "MODEL_PATH = MAIN_PATH + \"/models\"\n",
    "LOG_PATH = MAIN_PATH + \"/logs\"\n",
    "\n",
    "BEST_VAL_SCORE = 0\n",
    "BEST_MODEL = None\n",
    "HISTORY = []  # Initialize history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "global config\n",
    "config = load_config('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_metrics(history_dict: dict):\n",
    "    total_plots = len(history_dict)\n",
    "    cols = total_plots // 2\n",
    "    rows = total_plots // cols\n",
    "    if total_plots % cols != 0:\n",
    "        rows += 1\n",
    "\n",
    "    pos = range(1, total_plots + 1)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (key, value) in enumerate(history_dict.items()):\n",
    "        plt.subplot(rows, cols, pos[i])\n",
    "        plt.plot(range(len(value)), value)\n",
    "        plt.title(str(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df():\n",
    "    df = pd.read_csv(MAIN_PATH + \"/data/result_df.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_missing_values(numpy_data):\n",
    "    numpy_data['x_train'], numpy_data['y_train'] = Remove_missing_values(numpy_data['x_train'], numpy_data['y_train'])\n",
    "    numpy_data['x_val'], numpy_data['y_val'] = Remove_missing_values(numpy_data['x_val'], numpy_data['y_val'])\n",
    "    numpy_data['x_test_1'], numpy_data['y_test_1'] = Remove_missing_values(numpy_data['x_test_1'], numpy_data['y_test_1'])\n",
    "    numpy_data['x_test_2'], numpy_data['y_test_2'] = Remove_missing_values(numpy_data['x_test_2'], numpy_data['y_test_2'])\n",
    "    \n",
    "    return numpy_data\n",
    "\n",
    "def Remove_missing_values(x_data, y_data):\n",
    "    # Check if y_data contains missing values (NaNs) and remove corresponding x_data rows\n",
    "    valid_indices = ~np.isnan(y_data)  # Find valid (non-NaN) indices in y_data\n",
    "    x_clean = x_data[valid_indices]\n",
    "    y_clean = y_data[valid_indices]\n",
    "    return x_clean, y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_numpy_files(data_path):\n",
    "    numpy_data = {}\n",
    "    \n",
    "    for file_name in os.listdir(data_path):\n",
    "        if file_name.endswith('.npy'):\n",
    "            file_path = os.path.join(data_path, file_name)\n",
    "            numpy_data[file_name[:-4]] = np.load(file_path)  # Store in dict\n",
    "    \n",
    "    # Clean data by removing rows where y_* contains missing values\n",
    "    numpy_data = Clean_missing_values(numpy_data)\n",
    "\n",
    "    return numpy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(df, label_column):\n",
    "    vals_dict = {}\n",
    "    for i in df[label_column]:\n",
    "        if i in vals_dict.keys():\n",
    "            vals_dict[i] += 1\n",
    "        else:\n",
    "            vals_dict[i] = 1\n",
    "    total = sum(vals_dict.values())\n",
    "    weight_dict = {k: (1 - (v / total)) for k, v in vals_dict.items()}\n",
    "\n",
    "    print(f\"Weight dict for model: {weight_dict}\")\n",
    "    return weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(given_kernel_size):\n",
    "    input_layer = keras.Input(shape=(config['input_shape'], config['input_features']))\n",
    "    \n",
    "    x = layers.Conv1D(filters=32, kernel_size=given_kernel_size, activation=config['activation'], padding=\"same\", kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters=64, kernel_size=given_kernel_size, activation=config['activation'], padding=\"same\", kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters=128, kernel_size=given_kernel_size, activation=config['activation'], padding=\"same\", kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation=config['activation'], kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(256, activation=config['activation'], kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compile_model(kernel_size):\n",
    "    model = create_model(kernel_size)\n",
    "    optimizer = keras.optimizers.Adam(amsgrad=True, learning_rate=config['learning_rate'])\n",
    "    loss = keras.losses.BinaryCrossentropy()\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "            keras.metrics.AUC(name='auc'),\n",
    "            keras.metrics.Precision(name='precision'),\n",
    "            keras.metrics.Recall(name='recall'),\n",
    "            F1Score(name='f1_score')\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitDatasetForFolds(train_index, validation_index, fold_nr, numpy_data):\n",
    "    print(f\"Training fold {fold_nr}...\")\n",
    "\n",
    "    # Split the data into train sets for this fold.\n",
    "    x_train_fold = numpy_data['x_train'][train_index]\n",
    "    y_train_fold = numpy_data['y_train'][train_index]\n",
    "\n",
    "    print(f\"x_val shape: {numpy_data['x_val'].shape}\")\n",
    "    print(f\"y_val shape: {numpy_data['y_val'].shape}\")\n",
    "    \n",
    "    # Ensure to use only the training set indices\n",
    "    x_validation_fold = numpy_data['x_val'][:len(validation_index)]  # Taking the first `len(validation_index)` samples\n",
    "    y_validation_fold = numpy_data['y_val'][:len(validation_index)]\n",
    "\n",
    "    # Create tf.data.Datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train_fold, y_train_fold))\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices((x_validation_fold, y_validation_fold))\n",
    "    test_dataset_subject1 = tf.data.Dataset.from_tensor_slices((numpy_data['x_test_1'], numpy_data['y_test_1']))\t\n",
    "    test_dataset_subject2 = tf.data.Dataset.from_tensor_slices((numpy_data['x_test_2'], numpy_data['y_test_2']))\n",
    "    \n",
    "    # Shuffling and batching the datasets\n",
    "    train_dataset = train_dataset.shuffle(config['shuffle_buffer_size']).batch(config['batch_size'])\n",
    "    validation_dataset = validation_dataset.shuffle(config['shuffle_buffer_size']).batch(config['batch_size'])\n",
    "    test_dataset_subject1 = test_dataset_subject1.batch(config['batch_size'])\n",
    "    test_dataset_subject2 = test_dataset_subject2.batch(config['batch_size'])\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset_subject1, test_dataset_subject2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_native(data):\n",
    "    \"\"\"Recursively convert numpy types to native python types.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {key: convert_to_native(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_to_native(item) for item in data]\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return data.tolist()  # Convert numpy array to list\n",
    "    elif isinstance(data, (np.float32, np.float64)):\n",
    "        return data.item()  # Convert single value numpy float to Python float\n",
    "    else:\n",
    "        return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history_to_json(history, fold_number, best_model):\n",
    "    \"\"\"Save the training history and best model path to a JSON file.\"\"\"\n",
    "    try:\n",
    "        history_data = {\n",
    "            \"history\": convert_to_native(history.history),\n",
    "            \"best_model\": best_model\n",
    "        }\n",
    "        \n",
    "        history_file_path = os.path.join(LOG_PATH, f\"history_fold_{fold_number}.json\")\n",
    "        with open(history_file_path, 'w') as json_file:\n",
    "            json.dump(history_data, json_file)  # Write the history and best model to a JSON file\n",
    "        print(f\"History and best model saved to {history_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving history: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvclive import Live\n",
    "from dvclive.keras import DVCLiveCallback\n",
    "\n",
    "def Train_fold(train_index, val_index, fold_number, numpy_data, weight_dict, live, kernel_size):\n",
    "    global BEST_VAL_SCORE, HISTORY \n",
    "\n",
    "    # Split data into training and validation sets for this fold\n",
    "    train_dataset, validation_dataset, test_sj1, test_sj2 = SplitDatasetForFolds(train_index, val_index, fold_number, numpy_data)\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = Compile_model(kernel_size)\n",
    "    model.summary()\n",
    "\n",
    "    # Set up DVC Live callback for this fold\n",
    "    live_callback = DVCLiveCallback()\n",
    "\n",
    "    # Set up other callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(MODEL_PATH, f\"best_model_fold_{fold_number}.keras\"),\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_accuracy\"\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001),\n",
    "        live_callback\n",
    "    ]\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=5,\n",
    "        validation_data=validation_dataset,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=weight_dict\n",
    "    )\n",
    "\n",
    "    fold_performance = model.evaluate(train_dataset, batch_size=config['batch_size'], verbose=0)\n",
    "    print(f\"Train accuracy for fold {fold_number}: {fold_performance[1]}\")\n",
    "\n",
    "    return fold_performance[1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_validation_training(numpy_data, weight_dict, kernel_size):\n",
    "    global fold_number\n",
    "    fold_number = 1\n",
    "    scores = list()\n",
    "\n",
    "    os.makedirs(MODEL_PATH, exist_ok=True)  # Ensure the model path exists\n",
    "    # Initialize KFold with the number of splits\n",
    "    kfold = KFold(n_splits=config['folds'], shuffle=True, random_state=42)\n",
    "\n",
    "    try:\n",
    "        for train_index, val_index in kfold.split(numpy_data['x_train']):\n",
    "            print(f\"Training fold {fold_number}\")\n",
    "\n",
    "            live = Live()  # Start a new DVCLive run for this fold\n",
    "\n",
    "            # Train the current fold\n",
    "            score = Train_fold(train_index, val_index, fold_number, numpy_data, weight_dict, live, kernel_size)\n",
    "        \n",
    "            score = score * 100.0\n",
    "            print('>p=%d #%d: %.3f'% (kernel_size, fold_number+1, score))\n",
    "            scores.append(score)\n",
    "\n",
    "            fold_number += 1\n",
    "        return scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during cross-validation training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores, params):\n",
    "\tprint(scores, params)\n",
    "\t# summarize mean and standard deviation\n",
    "\tfor i in range(len(scores)):\n",
    "\t\tm, s = mean(scores[i]), std(scores[i])\n",
    "\t\tprint('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "\t# boxplot of scores\n",
    "\tplt.boxplot(scores, labels=params)\n",
    "\tplt.xlabel('Kernel Size')\n",
    "\tplt.ylabel('Score')\n",
    "\tplt.title('Model Performance by Kernel Size')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        df = load_df()\n",
    "        numpy_data = gather_numpy_files(DATA_PATH)\n",
    "\n",
    "        # test each parameter\n",
    "        all_scores = list()\n",
    "\n",
    "        # Calculate weights\n",
    "        weight_dict = calculate_class_weights(df, 'downsampled_label')\n",
    "        for kernel_size in config['kernel_sizes']:\n",
    "            print(f\"Running model with kernel size: {kernel_size}\")\n",
    "            # Train model\n",
    "            scores = Cross_validation_training(numpy_data, weight_dict, kernel_size)\n",
    "            all_scores.append(scores)\n",
    "        # summarize results\n",
    "\n",
    "        print(\"Cross-validation training completed.\\n\")\n",
    "\n",
    "        return all_scores\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in main: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight dict for model: {0: 0.11450662739322537, 1: 0.8854933726067746}\n",
      "Running model with kernel size: 3\n",
      "Training fold 1\n",
      "Training fold 1...\n",
      "x_val shape: (4988, 32, 1)\n",
      "y_val shape: (4988,)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 1)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 32)            128       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32)           128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 16, 64)            6208      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 8, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 128)            24704     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 128)           512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 426,177\n",
      "Trainable params: 425,729\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Starting training...\n",
      "Epoch 1/5\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.9043 - binary_accuracy: 0.7606 - auc: 0.9097 - precision: 0.6909 - recall: 0.9470 - f1_score: 0.7989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goert\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:2319: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 13s 36ms/step - loss: 0.9029 - binary_accuracy: 0.7616 - auc: 0.9103 - precision: 0.6928 - recall: 0.9475 - f1_score: 0.8004 - val_loss: 2.7208 - val_binary_accuracy: 0.5000 - val_auc: 0.5978 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1_score: 0.6667 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.6006 - binary_accuracy: 0.7624 - auc: 0.9150 - precision: 0.6877 - recall: 0.9644 - f1_score: 0.8028WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.5995 - binary_accuracy: 0.7637 - auc: 0.9156 - precision: 0.6901 - recall: 0.9648 - f1_score: 0.8046 - val_loss: 2.8693 - val_binary_accuracy: 0.5000 - val_auc: 0.6815 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1_score: 0.6667 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.4150 - binary_accuracy: 0.7642 - auc: 0.9172 - precision: 0.6890 - recall: 0.9705 - f1_score: 0.8059WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.4150 - binary_accuracy: 0.7642 - auc: 0.9172 - precision: 0.6890 - recall: 0.9705 - f1_score: 0.8059 - val_loss: 2.1583 - val_binary_accuracy: 0.5305 - val_auc: 0.7909 - val_precision: 0.5157 - val_recall: 0.9992 - val_f1_score: 0.6803 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.3020 - binary_accuracy: 0.7732 - auc: 0.9234 - precision: 0.6967 - recall: 0.9749 - f1_score: 0.8126WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.3020 - binary_accuracy: 0.7732 - auc: 0.9234 - precision: 0.6967 - recall: 0.9749 - f1_score: 0.8126 - val_loss: 2.0830 - val_binary_accuracy: 0.5307 - val_auc: 0.7819 - val_precision: 0.5158 - val_recall: 0.9992 - val_f1_score: 0.6804 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.2395 - binary_accuracy: 0.7398 - auc: 0.9229 - precision: 0.6624 - recall: 0.9786 - f1_score: 0.7900WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2389 - binary_accuracy: 0.7415 - auc: 0.9231 - precision: 0.6657 - recall: 0.9790 - f1_score: 0.7925 - val_loss: 2.2249 - val_binary_accuracy: 0.5523 - val_auc: 0.7695 - val_precision: 0.5277 - val_recall: 0.9976 - val_f1_score: 0.6902 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to validate remotes. Disabling auto push: config file error: no remote specified in d:\\Master of Applied IT. Create a default remote with\n",
      "    dvc remote add -d <remote name> <remote url>\n",
      "WARNING: The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\tnotebooks/config.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for fold 1: 0.5549863576889038\n",
      ">p=3 #2: 55.499\n",
      "Training fold 2\n",
      "Training fold 2...\n",
      "x_val shape: (4988, 32, 1)\n",
      "y_val shape: (4988,)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 1)]           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 32, 32)            128       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 16, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 16, 64)            6208      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 8, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 8, 128)            24704     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 128)           512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 4, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 426,177\n",
      "Trainable params: 425,729\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Starting training...\n",
      "Epoch 1/5\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.9193 - binary_accuracy: 0.7412 - auc: 0.8918 - precision: 0.6681 - recall: 0.9446 - f1_score: 0.7826WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 9s 36ms/step - loss: 0.9180 - binary_accuracy: 0.7423 - auc: 0.8920 - precision: 0.6702 - recall: 0.9452 - f1_score: 0.7843 - val_loss: 2.6966 - val_binary_accuracy: 0.5000 - val_auc: 0.6582 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1_score: 0.6667 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.6187 - binary_accuracy: 0.7426 - auc: 0.9078 - precision: 0.6644 - recall: 0.9613 - f1_score: 0.7857WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.6168 - binary_accuracy: 0.7444 - auc: 0.9087 - precision: 0.6681 - recall: 0.9621 - f1_score: 0.7886 - val_loss: 3.0656 - val_binary_accuracy: 0.5000 - val_auc: 0.6515 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1_score: 0.6667 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.4264 - binary_accuracy: 0.7490 - auc: 0.9141 - precision: 0.6716 - recall: 0.9655 - f1_score: 0.7922WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.4264 - binary_accuracy: 0.7490 - auc: 0.9141 - precision: 0.6716 - recall: 0.9655 - f1_score: 0.7922 - val_loss: 2.4271 - val_binary_accuracy: 0.5074 - val_auc: 0.7632 - val_precision: 0.5037 - val_recall: 1.0000 - val_f1_score: 0.6700 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.3086 - binary_accuracy: 0.7464 - auc: 0.9230 - precision: 0.6674 - recall: 0.9735 - f1_score: 0.7919WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.3086 - binary_accuracy: 0.7464 - auc: 0.9230 - precision: 0.6674 - recall: 0.9735 - f1_score: 0.7919 - val_loss: 2.0422 - val_binary_accuracy: 0.5575 - val_auc: 0.7752 - val_precision: 0.5306 - val_recall: 0.9968 - val_f1_score: 0.6926 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.2427 - binary_accuracy: 0.7365 - auc: 0.9202 - precision: 0.6573 - recall: 0.9786 - f1_score: 0.7864WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.2427 - binary_accuracy: 0.7365 - auc: 0.9202 - precision: 0.6573 - recall: 0.9786 - f1_score: 0.7864 - val_loss: 1.8682 - val_binary_accuracy: 0.6159 - val_auc: 0.7887 - val_precision: 0.5665 - val_recall: 0.9876 - val_f1_score: 0.7200 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to validate remotes. Disabling auto push: config file error: no remote specified in d:\\Master of Applied IT. Create a default remote with\n",
      "    dvc remote add -d <remote name> <remote url>\n",
      "WARNING: The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\tnotebooks/config.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for fold 2: 0.6302937269210815\n",
      ">p=3 #3: 63.029\n",
      "Cross-validation training completed.\n",
      "\n",
      "[[55.49863576889038, 63.029372692108154]] [3]\n",
      "Param=3: 59.264% (+/-3.765)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goert\\AppData\\Local\\Temp\\ipykernel_23312\\821211489.py:9: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(scores, labels=params)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_scores = main()\n",
    "\n",
    "summarize_results(all_scores, config['kernel_sizes'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
